{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tR9ECn3QtoeY"
      },
      "source": [
        "### Install Mediapipe(세션 재시작 필요)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ipKyFljfvoTk",
        "outputId": "b7254e19-fa79-4d92-dd9d-439192504afb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting mediapipe\n",
            "  Downloading mediapipe-0.10.21-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.12/dist-packages (from mediapipe) (25.4.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.12/dist-packages (from mediapipe) (25.9.23)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.12/dist-packages (from mediapipe) (0.7.2)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.12/dist-packages (from mediapipe) (0.7.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from mediapipe) (3.10.0)\n",
            "Collecting numpy<2 (from mediapipe)\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.12/dist-packages (from mediapipe) (4.12.0.88)\n",
            "Collecting protobuf<5,>=4.25.3 (from mediapipe)\n",
            "  Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Collecting sounddevice>=0.4.4 (from mediapipe)\n",
            "  Downloading sounddevice-0.5.3-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from mediapipe) (0.2.1)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.12/dist-packages (from sounddevice>=0.4.4->mediapipe) (2.0.0)\n",
            "Requirement already satisfied: ml_dtypes>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from jax->mediapipe) (0.5.4)\n",
            "INFO: pip is looking at multiple versions of jax to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting jax (from mediapipe)\n",
            "  Downloading jax-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting jaxlib (from mediapipe)\n",
            "  Downloading jaxlib-0.8.1-cp312-cp312-manylinux_2_27_x86_64.whl.metadata (1.3 kB)\n",
            "Collecting jax (from mediapipe)\n",
            "  Downloading jax-0.8.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting jaxlib (from mediapipe)\n",
            "  Downloading jaxlib-0.8.0-cp312-cp312-manylinux_2_27_x86_64.whl.metadata (1.3 kB)\n",
            "Collecting jax (from mediapipe)\n",
            "  Downloading jax-0.7.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting jaxlib (from mediapipe)\n",
            "  Downloading jaxlib-0.7.1-cp312-cp312-manylinux_2_27_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.12/dist-packages (from jax->mediapipe) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.12 in /usr/local/lib/python3.12/dist-packages (from jax->mediapipe) (1.16.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (4.61.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
            "INFO: pip is looking at multiple versions of opencv-contrib-python to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting opencv-contrib-python (from mediapipe)\n",
            "  Downloading opencv_contrib_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.23)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\n",
            "Downloading mediapipe-0.10.21-cp312-cp312-manylinux_2_28_x86_64.whl (35.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.6/35.6 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sounddevice-0.5.3-py3-none-any.whl (32 kB)\n",
            "Downloading jax-0.7.1-py3-none-any.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jaxlib-0.7.1-cp312-cp312-manylinux_2_27_x86_64.whl (81.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.2/81.2 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_contrib_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (69.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: protobuf, numpy, sounddevice, opencv-contrib-python, jaxlib, jax, mediapipe\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.5\n",
            "    Uninstalling protobuf-5.29.5:\n",
            "      Successfully uninstalled protobuf-5.29.5\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: opencv-contrib-python\n",
            "    Found existing installation: opencv-contrib-python 4.12.0.88\n",
            "    Uninstalling opencv-contrib-python-4.12.0.88:\n",
            "      Successfully uninstalled opencv-contrib-python-4.12.0.88\n",
            "  Attempting uninstall: jaxlib\n",
            "    Found existing installation: jaxlib 0.7.2\n",
            "    Uninstalling jaxlib-0.7.2:\n",
            "      Successfully uninstalled jaxlib-0.7.2\n",
            "  Attempting uninstall: jax\n",
            "    Found existing installation: jax 0.7.2\n",
            "    Uninstalling jax-0.7.2:\n",
            "      Successfully uninstalled jax-0.7.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "ydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 4.25.8 which is incompatible.\n",
            "opentelemetry-proto 1.37.0 requires protobuf<7.0,>=5.0, but you have protobuf 4.25.8 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.8 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed jax-0.7.1 jaxlib-0.7.1 mediapipe-0.10.21 numpy-1.26.4 opencv-contrib-python-4.11.0.86 protobuf-4.25.8 sounddevice-0.5.3\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "c2022ff7f8d54325b9b3b3171c5ced8f",
              "pip_warning": {
                "packages": [
                  "google",
                  "numpy"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install mediapipe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qe96XXMqoQgq"
      },
      "source": [
        "### Set Random Seed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "_066kN10oQgr"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# 시드값 설정\n",
        "SEED = 42\n",
        "\n",
        "def set_global_seed(seed):\n",
        "    # 1. Python 기본 시드 고정\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    random.seed(seed)\n",
        "\n",
        "    # 2. NumPy 시드 고정\n",
        "    np.random.seed(seed)\n",
        "\n",
        "    # 3. TensorFlow(Keras) 시드 고정\n",
        "    tf.random.set_seed(seed)\n",
        "\n",
        "    # 4. TensorFlow 연산 결정론적(Deterministic) 설정 (TF 2.7+ 버전 권장)\n",
        "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "    os.environ['TF_CUDNN_DETERMINISTIC'] = '1' # GPU 사용 시\n",
        "\n",
        "    try:\n",
        "        tf.config.experimental.enable_op_determinism()\n",
        "    except AttributeError:\n",
        "        print(\"경고: 설치된 TensorFlow 버전에서 enable_op_determinism을 지원하지 않을 수 있습니다.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewIzrSdCtoeg"
      },
      "source": [
        "### Helper Func"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bXoyRvJQtoeh"
      },
      "outputs": [],
      "source": [
        "def calculate_angle(a, b, c):\n",
        "    \"\"\"\n",
        "    세 개의 랜드마크(a, b, c)를 받아 b 지점의 각도와 신뢰도(가시성 곱)를 반환합니다.\n",
        "    \"\"\"\n",
        "    reliability = a[3] * b[3] * c[3]\n",
        "\n",
        "    if a[3] < 0.5 or b[3] < 0.5 or c[3] < 0.5:\n",
        "        return None, reliability\n",
        "\n",
        "    a_xyz = a[:3]\n",
        "    b_xyz = b[:3]\n",
        "    c_xyz = c[:3]\n",
        "\n",
        "    try:\n",
        "        ba = a_xyz - b_xyz\n",
        "        bc = c_xyz - b_xyz\n",
        "\n",
        "        cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))\n",
        "        cosine_angle = np.clip(cosine_angle, -1.0, 1.0)\n",
        "        angle = np.arccos(cosine_angle)\n",
        "\n",
        "        return np.degrees(angle), reliability\n",
        "    except (ZeroDivisionError, RuntimeWarning):\n",
        "        return None, reliability\n",
        "\n",
        "def calculate_plane_normal(a, b, c):\n",
        "    \"\"\"\n",
        "    세 개의 랜드마크(a, b, c)로 정의된 평면의 법선 벡터(Normal Vector)를 반환합니다.\n",
        "    반환값: [x, y, z] (정규화된 벡터), reliability\n",
        "    순서는 a -> b -> c 순으로 오른손 법칙을 따릅니다.\n",
        "    \"\"\"\n",
        "    # 신뢰도 계산\n",
        "    reliability = a[3] * b[3] * c[3]\n",
        "\n",
        "    # 가시성이 낮은 랜드마크가 포함되면 계산 불가\n",
        "    if a[3] < 0.5 or b[3] < 0.5 or c[3] < 0.5:\n",
        "        return None, reliability\n",
        "\n",
        "    a_xyz = a[:3]\n",
        "    b_xyz = b[:3]\n",
        "    c_xyz = c[:3]\n",
        "\n",
        "    try:\n",
        "        # 두 개의 벡터 생성 (a -> b, a -> c)\n",
        "        v1 = b_xyz - a_xyz\n",
        "        v2 = c_xyz - a_xyz\n",
        "\n",
        "        # 외적(Cross Product)을 통해 법선 벡터 계산\n",
        "        normal = np.cross(v1, v2)\n",
        "\n",
        "        # 벡터 정규화 (크기를 1로 만듦)\n",
        "        norm_length = np.linalg.norm(normal)\n",
        "        if norm_length == 0:\n",
        "            return None, reliability\n",
        "\n",
        "        normalized_normal = normal / norm_length\n",
        "\n",
        "        return normalized_normal, reliability\n",
        "\n",
        "    except (RuntimeWarning, Exception):\n",
        "        return None, reliability\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjRAbBUKtoel"
      },
      "source": [
        "## Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wRzhgFTUtoep"
      },
      "outputs": [],
      "source": [
        "def feature_engineering(landmarks):\n",
        "    \"\"\"\n",
        "    landmarks: (33, 4) shape의 numpy array [x, y, z, visibility]\n",
        "    \"\"\"\n",
        "    if landmarks is None: return None\n",
        "    NOSE = 0\n",
        "    L_EYE, R_EYE = 2, 5\n",
        "    L_EAR, R_EAR = 7, 8\n",
        "    L_SHOULDER, R_SHOULDER = 11, 12\n",
        "    L_ELBOW, R_ELBOW = 13, 14\n",
        "    L_WRIST, R_WRIST = 15, 16\n",
        "    L_HIP, R_HIP = 23, 24\n",
        "\n",
        "    normal_features, normal_rels = [], []\n",
        "\n",
        "    face_normal, face_rel = calculate_plane_normal(landmarks[NOSE], landmarks[L_EYE], landmarks[R_EYE])\n",
        "    normal_features.append(face_normal)\n",
        "    normal_rels.append(face_rel)\n",
        "\n",
        "    sh_nose_normal, sh_nose_rel = calculate_plane_normal(landmarks[L_SHOULDER], landmarks[R_SHOULDER], landmarks[NOSE])\n",
        "    normal_features.append(sh_nose_normal)\n",
        "    normal_rels.append(sh_nose_rel)\n",
        "\n",
        "    flat_normals_vec = []\n",
        "    for vec in normal_features:\n",
        "        if vec is not None: flat_normals_vec.extend(vec)\n",
        "        else: flat_normals_vec.extend([0.0, 0.0, 0.0])\n",
        "\n",
        "    final_features = flat_normals_vec + normal_rels\n",
        "    return np.array(final_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOhAHEgQoQgw"
      },
      "source": [
        "## 데이터셋 전처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7f9ogtyVoQgx",
        "outputId": "69f4595a-152a-4008-a9c6-73537512b158"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "데이터 전처리 중...\n"
          ]
        }
      ],
      "source": [
        "# .npy 파일 경로\n",
        "X_DATA_PATH = 'X_train.npy'\n",
        "Y_DATA_PATH = 'Y_train.npy'\n",
        "X_VAL_PATH = 'X_val.npy'\n",
        "Y_VAL_PATH = 'Y_val.npy'\n",
        "X_TEST_PATH = 'X_test.npy'\n",
        "Y_TEST_PATH = 'Y_test.npy'\n",
        "\n",
        "required_files = [\n",
        "    X_DATA_PATH, Y_DATA_PATH,\n",
        "    X_VAL_PATH, Y_VAL_PATH,\n",
        "    X_TEST_PATH, Y_TEST_PATH\n",
        "]\n",
        "\n",
        "if not all(os.path.exists(path) for path in required_files):\n",
        "    print(\"=\"*50)\n",
        "    print(\"데이터셋 파일이 스크립트와 동일한 디렉토리에 있는지 확인해주세요.\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "try:\n",
        "    raw_landmarks = np.load(X_DATA_PATH)\n",
        "    labels = np.load(Y_DATA_PATH)\n",
        "    raw_val = np.load(X_VAL_PATH)\n",
        "    labels_val = np.load(Y_VAL_PATH)\n",
        "    raw_test = np.load(X_TEST_PATH)\n",
        "    labels_test = np.load(Y_TEST_PATH)\n",
        "\n",
        "    # 데이터 처리 함수\n",
        "    def process_data(raw_x, raw_y):\n",
        "        processed_x, processed_y = [], []\n",
        "        for i, lm in enumerate(raw_x):\n",
        "            fv = feature_engineering(lm)\n",
        "            if fv is not None:\n",
        "                processed_x.append(fv)\n",
        "                processed_y.append(raw_y[i])\n",
        "        return np.array(processed_x), np.array(processed_y)\n",
        "\n",
        "    print(\"데이터 전처리 중...\")\n",
        "    X_train, y_train = process_data(raw_landmarks, labels)\n",
        "    X_val, y_val = process_data(raw_val, labels_val)\n",
        "    X_test, y_test = process_data(raw_test, labels_test)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"오류 발생: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nA508CHTtoeq"
      },
      "source": [
        "## MLP(val_accuracy = 0.9613)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NOVr50REq-KD",
        "outputId": "44690d77-6cc8-45f3-ddcf-20a6b8160a72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "학습 데이터: 2139개 / 테스트 데이터: 250개\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_15\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_15\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_45 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,792</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_46 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_47 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_45 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m9,792\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_30 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_46 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_31 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_47 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,905</span> (46.50 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m11,905\u001b[0m (46.50 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,905</span> (46.50 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m11,905\u001b[0m (46.50 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "모델 학습 시작...\n",
            "Epoch 1/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5703 - loss: 0.7554 - val_accuracy: 0.5189 - val_loss: 0.7173\n",
            "Epoch 2/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6635 - loss: 0.5885 - val_accuracy: 0.5236 - val_loss: 0.6415\n",
            "Epoch 3/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7186 - loss: 0.4968 - val_accuracy: 0.5236 - val_loss: 0.6972\n",
            "Epoch 4/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7648 - loss: 0.4426 - val_accuracy: 0.5991 - val_loss: 0.5271\n",
            "Epoch 5/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7629 - loss: 0.4251 - val_accuracy: 0.6226 - val_loss: 0.4698\n",
            "Epoch 6/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8226 - loss: 0.3657 - val_accuracy: 0.5425 - val_loss: 0.8731\n",
            "Epoch 7/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8297 - loss: 0.3606 - val_accuracy: 0.9292 - val_loss: 0.2338\n",
            "Epoch 8/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8726 - loss: 0.3165 - val_accuracy: 0.6038 - val_loss: 0.6649\n",
            "Epoch 9/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8641 - loss: 0.2992 - val_accuracy: 0.7877 - val_loss: 0.5125\n",
            "Epoch 10/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8540 - loss: 0.3137 - val_accuracy: 0.8821 - val_loss: 0.2979\n",
            "Epoch 11/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8784 - loss: 0.2805 - val_accuracy: 0.6368 - val_loss: 0.4775\n",
            "Epoch 12/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8887 - loss: 0.2770 - val_accuracy: 0.6557 - val_loss: 0.4945\n",
            "Epoch 13/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8937 - loss: 0.2617 - val_accuracy: 0.8868 - val_loss: 0.2626\n",
            "Epoch 14/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9166 - loss: 0.2191 - val_accuracy: 0.9340 - val_loss: 0.2293\n",
            "Epoch 15/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9166 - loss: 0.2123 - val_accuracy: 0.5660 - val_loss: 1.0846\n",
            "Epoch 16/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9066 - loss: 0.2285 - val_accuracy: 0.6415 - val_loss: 0.7797\n",
            "Epoch 17/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9277 - loss: 0.1971 - val_accuracy: 0.7406 - val_loss: 0.4945\n",
            "Epoch 18/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9136 - loss: 0.2014 - val_accuracy: 0.5755 - val_loss: 0.9397\n",
            "Epoch 19/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9240 - loss: 0.1892 - val_accuracy: 0.9104 - val_loss: 0.2466\n",
            "Epoch 20/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9283 - loss: 0.1841 - val_accuracy: 0.6274 - val_loss: 0.9049\n",
            "Epoch 21/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9359 - loss: 0.1571 - val_accuracy: 0.8774 - val_loss: 0.3080\n",
            "Epoch 22/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9332 - loss: 0.1667 - val_accuracy: 0.7311 - val_loss: 0.4579\n",
            "Epoch 23/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9382 - loss: 0.1689 - val_accuracy: 0.6368 - val_loss: 0.9737\n",
            "Epoch 24/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9417 - loss: 0.1538 - val_accuracy: 0.6321 - val_loss: 0.9919\n",
            "Epoch 25/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9439 - loss: 0.1459 - val_accuracy: 0.6462 - val_loss: 0.6824\n",
            "Epoch 26/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9470 - loss: 0.1442 - val_accuracy: 0.7500 - val_loss: 0.6802\n",
            "Epoch 27/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9396 - loss: 0.1660 - val_accuracy: 0.8585 - val_loss: 0.3653\n",
            "Epoch 28/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9279 - loss: 0.1800 - val_accuracy: 0.9151 - val_loss: 0.2605\n",
            "Epoch 29/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9495 - loss: 0.1319 - val_accuracy: 0.6792 - val_loss: 0.8972\n",
            "Epoch 30/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9557 - loss: 0.1327 - val_accuracy: 0.6981 - val_loss: 0.8145\n",
            "Epoch 31/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9613 - loss: 0.1179 - val_accuracy: 0.6651 - val_loss: 0.9434\n",
            "Epoch 32/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9518 - loss: 0.1335 - val_accuracy: 0.5755 - val_loss: 1.8782\n",
            "Epoch 33/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9309 - loss: 0.1498 - val_accuracy: 0.6840 - val_loss: 0.7244\n",
            "Epoch 34/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9595 - loss: 0.1165 - val_accuracy: 0.7689 - val_loss: 0.6621\n",
            "모델 학습 완료.\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8944 - loss: 0.3837 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "검증 데이터 평가 결과:\n",
            "Loss (손실): 0.2293\n",
            "Accuracy (정확도): 0.9340\n",
            "학습된 모델을 'All_pose_classifier_keras.h5'로 저장했습니다.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Input\n",
        "\n",
        "def build_model(input_shape):\n",
        "    model = Sequential([\n",
        "        Input(shape=(input_shape,)),\n",
        "        # kernel_initializer에도 시드를 명시하면 더 안전함\n",
        "        Dense(64, activation='relu', kernel_initializer=tf.keras.initializers.GlorotUniform(seed=SEED)),\n",
        "        # Dropout에 seed 인자 추가 (중요!)\n",
        "        Dropout(0.3, seed=SEED),\n",
        "\n",
        "        Dense(32, activation='relu', kernel_initializer=tf.keras.initializers.GlorotUniform(seed=SEED)),\n",
        "        Dropout(0.3, seed=SEED),\n",
        "\n",
        "        Dense(1, activation='sigmoid', kernel_initializer=tf.keras.initializers.GlorotUniform(seed=SEED))\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=[tf.keras.metrics.BinaryAccuracy(name='accuracy')])\n",
        "    return model\n",
        "\n",
        "# --- 메인 실행 로직 ---\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        if X_train.shape[0] == 0:\n",
        "            print(\"오류: 모든 샘플에서 특징 공학(각도 계산 등)에 실패했습니다.\")\n",
        "            print(\"데이터셋의 가시성(visibility) 값을 확인해주세요.\")\n",
        "        else:\n",
        "\n",
        "            print(f\"학습 데이터: {X_train.shape[0]}개 / 테스트 데이터: {X_test.shape[0]}개\")\n",
        "            set_global_seed(SEED)\n",
        "\n",
        "            # --- 4. 모델 학습 ---\n",
        "            # 1. 인덱스 배열 생성 (0부터 N-1까지)\n",
        "            indices = np.arange(X_train.shape[0])\n",
        "\n",
        "            # 2. 인덱스 무작위 섞기\n",
        "            np.random.shuffle(indices)\n",
        "\n",
        "            # 3. 섞인 인덱스로 X와 y 재배열 (짝 유지됨)\n",
        "            X_train = X_train[indices]\n",
        "            y_train = y_train[indices]\n",
        "\n",
        "            model = build_model(input_shape=X_train.shape[1])\n",
        "            model.summary()\n",
        "\n",
        "            print(\"\\n모델 학습 시작...\")\n",
        "            history = model.fit(\n",
        "                X_train,\n",
        "                y_train,\n",
        "                epochs=500,\n",
        "                batch_size=16,\n",
        "                validation_data=(X_val, y_val),\n",
        "                shuffle=False,\n",
        "                callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)]\n",
        "            )\n",
        "\n",
        "            print(\"모델 학습 완료.\")\n",
        "\n",
        "            loss, accuracy = model.evaluate(X_val, y_val)\n",
        "\n",
        "            print(f\"\\n검증 데이터 평가 결과:\")\n",
        "            print(f\"Loss (손실): {loss:.4f}\")\n",
        "            print(f\"Accuracy (정확도): {accuracy:.4f}\")\n",
        "\n",
        "            # --- 6. 모델 저장 ---\n",
        "            model.save(\"plane_pose_classifier_keras.h5\")\n",
        "            print(\"학습된 모델을 'plane_pose_classifier_keras.h5'로 저장했습니다.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"오류: 데이터셋 로드 또는 처리 중 예외 발생: {e}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Dkuzqwvtoev"
      },
      "source": [
        "## RandomForest (val_accuracy = 0.8688)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "stotQbNEf7cP",
        "outputId": "5da4709c-f517-4e3d-ac3f-09076d6b0953"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "데이터 셔플링 중...\n",
            "\n",
            "[Random Forest] 학습 시작 (데이터 개수: 2139개)...\n",
            "학습 완료.\n",
            "\n",
            "검증 데이터 평가 결과:\n",
            "Accuracy (정확도): 1.0000\n",
            "\n",
            "분류 보고서:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       110\n",
            "           1       1.00      1.00      1.00       102\n",
            "\n",
            "    accuracy                           1.00       212\n",
            "   macro avg       1.00      1.00      1.00       212\n",
            "weighted avg       1.00      1.00      1.00       212\n",
            "\n",
            "모델 저장 완료: 'All_pose_classifier_rf.pkl'\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import joblib  # scikit-learn 모델 저장용\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# --- 메인 실행 로직 ---\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        set_global_seed(SEED)\n",
        "        # --- 셔플링 (Shuffling) ---\n",
        "        print(\"데이터 셔플링 중...\")\n",
        "        indices = np.arange(X_train.shape[0])\n",
        "        np.random.shuffle(indices)\n",
        "        X_train = X_train[indices]\n",
        "        y_train = y_train[indices]\n",
        "\n",
        "        # --- Random Forest 모델 학습 ---\n",
        "        print(f\"\\n[Random Forest] 학습 시작 (데이터 개수: {len(X_train)}개)...\")\n",
        "        # n_estimators: 트리의 개수 (보통 100~500)\n",
        "        rf_model = RandomForestClassifier(n_estimators=100, n_jobs=-1)\n",
        "        rf_model.fit(X_train, y_train)\n",
        "        print(\"학습 완료.\")\n",
        "\n",
        "        # --- 모델 검증 ---\n",
        "        y_pred = rf_model.predict(X_val)\n",
        "        accuracy = accuracy_score(y_val, y_pred)\n",
        "\n",
        "        print(f\"\\n검증 데이터 평가 결과:\")\n",
        "        print(f\"Accuracy (정확도): {accuracy:.4f}\")\n",
        "        print(\"\\n분류 보고서:\")\n",
        "        print(classification_report(y_val, y_pred))\n",
        "\n",
        "        # --- 모델 저장 ---\n",
        "        joblib.dump(rf_model, \"plane_pose_classifier_rf.pkl\")\n",
        "        print(\"모델 저장 완료: 'plane_pose_classifier_rf.pkl'\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"오류 발생: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itZJbt5_toe1"
      },
      "source": [
        "## Support Vector Machine (val_accuracy = 0.9210)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqFSiCEcgOkM",
        "outputId": "90413446-a50f-4b88-f442-d71a2802f8f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "특징 벡터 차원: 152\n",
            "데이터 셔플링 중...\n",
            "\n",
            "[SVM] 학습 준비 (데이터 개수: 2139개)...\n",
            "교차 검증(Cross Validation) 진행 중...\n",
            " >> 5-Fold 검증 정확도: [0.92990654 0.94392523 0.95327103 0.94392523 0.94847775]\n",
            " >> 평균 검증 정확도: 0.9439\n",
            "최종 모델 학습 중...\n",
            "\n",
            "검증 데이터 평가 결과:\n",
            "Accuracy (정확도): 0.8726\n",
            "\n",
            "분류 보고서:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      1.00      0.89       110\n",
            "           1       1.00      0.74      0.85       102\n",
            "\n",
            "    accuracy                           0.87       212\n",
            "   macro avg       0.90      0.87      0.87       212\n",
            "weighted avg       0.90      0.87      0.87       212\n",
            "\n",
            "모델 저장 완료: 'All_pose_classifier_svm.pkl'\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import joblib\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# --- 메인 실행 로직 ---\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        set_global_seed(SEED)\n",
        "        print(f\"특징 벡터 차원: {X_train.shape[1]}\")\n",
        "\n",
        "        # --- 셔플링 (Shuffling) ---\n",
        "        print(\"데이터 셔플링 중...\")\n",
        "        indices = np.arange(X_train.shape[0])\n",
        "        np.random.shuffle(indices)\n",
        "        X_train = X_train[indices]\n",
        "        y_train = y_train[indices]\n",
        "\n",
        "        # --- SVM 모델 정의 ---\n",
        "        print(f\"\\n[SVM] 학습 준비 (데이터 개수: {len(X_train)}개)...\")\n",
        "\n",
        "        # SVM 파이프라인 (스케일링 + SVM)\n",
        "        svm_model = make_pipeline(\n",
        "            StandardScaler(),\n",
        "            SVC(kernel='rbf', C=1.0, probability=True)\n",
        "        )\n",
        "\n",
        "        # --- 1. 교차 검증 (Validation) ---\n",
        "        print(\"교차 검증(Cross Validation) 진행 중...\")\n",
        "        val_scores = cross_val_score(svm_model, X_train, y_train, cv=5)\n",
        "        print(f\" >> 5-Fold 검증 정확도: {val_scores}\")\n",
        "        print(f\" >> 평균 검증 정확도: {np.mean(val_scores):.4f}\")\n",
        "\n",
        "        # --- 2. 전체 데이터로 최종 학습 ---\n",
        "        print(\"최종 모델 학습 중...\")\n",
        "        svm_model.fit(X_train, y_train)\n",
        "\n",
        "        # --- 모델 검증 ---\n",
        "        y_pred = svm_model.predict(X_val)\n",
        "        accuracy = accuracy_score(y_val, y_pred)\n",
        "\n",
        "        print(f\"\\n검증 데이터 평가 결과:\")\n",
        "        print(f\"Accuracy (정확도): {accuracy:.4f}\")\n",
        "        print(\"\\n분류 보고서:\")\n",
        "        print(classification_report(y_val, y_pred))\n",
        "\n",
        "        # --- 모델 저장 ---\n",
        "        joblib.dump(svm_model, \"plane_pose_classifier_svm.pkl\")\n",
        "        print(\"모델 저장 완료: 'plane_pose_classifier_svm.pkl'\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"오류 발생: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3jBv-xCtoe2"
      },
      "source": [
        "## Log_Regression(val_accuracy = 0.5708)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdNdfX0itoe3",
        "outputId": "2c26bb0c-93ee-4300-a724-28a893bc2d76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ 모델 학습 및 환경 준비 완료\n",
            "\n",
            "--- 🧪 모델 검증 결과 (Test Set) ---\n",
            "✅ 정확도: 94.81%\n",
            "\n",
            "[ 혼동 행렬 (Confusion Matrix) ]\n",
            "[[110   0]\n",
            " [ 11  91]]\n",
            "\n",
            "[ 분류 리포트 (Classification Report) ]\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            " Bad Posture (0)       0.91      1.00      0.95       110\n",
            "Good Posture (1)       1.00      0.89      0.94       102\n",
            "\n",
            "        accuracy                           0.95       212\n",
            "       macro avg       0.95      0.95      0.95       212\n",
            "    weighted avg       0.95      0.95      0.95       212\n",
            "\n",
            "-----------------------------------\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        "import mediapipe as mp\n",
        "import cv2\n",
        "\n",
        "set_global_seed(SEED)\n",
        "scaler = StandardScaler()\n",
        "print(\"데이터 셔플링 중...\")\n",
        "indices = np.arange(X_train.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "X_train = X_train[indices]\n",
        "y_train = y_train[indices]\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "\n",
        "log_reg_model = LogisticRegression(solver='liblinear')\n",
        "log_reg_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "print(\"✅ 모델 학습 및 환경 준비 완료\")\n",
        "\n",
        "# --- 2. 모델 검증 코드 ---\n",
        "print(\"\\n--- 🧪 모델 검증 결과 (Test Set) ---\")\n",
        "y_pred = log_reg_model.predict(X_val_scaled)\n",
        "\n",
        "# 정확도 (Accuracy)\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "print(f\"✅ 정확도: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# 혼동 행렬 (Confusion Matrix)\n",
        "print(\"\\n[ 혼동 행렬 (Confusion Matrix) ]\")\n",
        "print(confusion_matrix(y_val, y_pred))\n",
        "\n",
        "# 분류 리포트 (Precision, Recall, F1-score)\n",
        "# target_names는 0번 클래스와 1번 클래스의 이름을 지정합니다.\n",
        "print(\"\\n[ 분류 리포트 (Classification Report) ]\")\n",
        "print(classification_report(y_val, y_pred, target_names=['Bad Posture (0)', 'Good Posture (1)']))\n",
        "print(\"-----------------------------------\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python (motion_transformer)",
      "language": "python",
      "name": "motion_transformer"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.23"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
