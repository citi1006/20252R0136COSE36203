{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tR9ECn3QtoeY"
      },
      "source": [
        "### Install Mediapipe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ipKyFljfvoTk",
        "outputId": "c46ce667-085b-4931-edc3-a6303e8549c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mediapipe\n",
            "  Downloading mediapipe-0.10.21-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.12/dist-packages (from mediapipe) (25.4.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.12/dist-packages (from mediapipe) (25.9.23)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.12/dist-packages (from mediapipe) (0.7.2)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.12/dist-packages (from mediapipe) (0.7.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from mediapipe) (3.10.0)\n",
            "Collecting numpy<2 (from mediapipe)\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.12/dist-packages (from mediapipe) (4.12.0.88)\n",
            "Collecting protobuf<5,>=4.25.3 (from mediapipe)\n",
            "  Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Collecting sounddevice>=0.4.4 (from mediapipe)\n",
            "  Downloading sounddevice-0.5.3-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from mediapipe) (0.2.1)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.12/dist-packages (from sounddevice>=0.4.4->mediapipe) (2.0.0)\n",
            "Requirement already satisfied: ml_dtypes>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from jax->mediapipe) (0.5.4)\n",
            "INFO: pip is looking at multiple versions of jax to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting jax (from mediapipe)\n",
            "  Downloading jax-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting jaxlib (from mediapipe)\n",
            "  Downloading jaxlib-0.8.1-cp312-cp312-manylinux_2_27_x86_64.whl.metadata (1.3 kB)\n",
            "Collecting jax (from mediapipe)\n",
            "  Downloading jax-0.8.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting jaxlib (from mediapipe)\n",
            "  Downloading jaxlib-0.8.0-cp312-cp312-manylinux_2_27_x86_64.whl.metadata (1.3 kB)\n",
            "Collecting jax (from mediapipe)\n",
            "  Downloading jax-0.7.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting jaxlib (from mediapipe)\n",
            "  Downloading jaxlib-0.7.1-cp312-cp312-manylinux_2_27_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.12/dist-packages (from jax->mediapipe) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.12 in /usr/local/lib/python3.12/dist-packages (from jax->mediapipe) (1.16.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (4.61.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
            "INFO: pip is looking at multiple versions of opencv-contrib-python to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting opencv-contrib-python (from mediapipe)\n",
            "  Downloading opencv_contrib_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.23)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\n",
            "Downloading mediapipe-0.10.21-cp312-cp312-manylinux_2_28_x86_64.whl (35.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.6/35.6 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sounddevice-0.5.3-py3-none-any.whl (32 kB)\n",
            "Downloading jax-0.7.1-py3-none-any.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jaxlib-0.7.1-cp312-cp312-manylinux_2_27_x86_64.whl (81.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.2/81.2 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_contrib_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (69.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: protobuf, numpy, sounddevice, opencv-contrib-python, jaxlib, jax, mediapipe\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.5\n",
            "    Uninstalling protobuf-5.29.5:\n",
            "      Successfully uninstalled protobuf-5.29.5\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: opencv-contrib-python\n",
            "    Found existing installation: opencv-contrib-python 4.12.0.88\n",
            "    Uninstalling opencv-contrib-python-4.12.0.88:\n",
            "      Successfully uninstalled opencv-contrib-python-4.12.0.88\n",
            "  Attempting uninstall: jaxlib\n",
            "    Found existing installation: jaxlib 0.7.2\n",
            "    Uninstalling jaxlib-0.7.2:\n",
            "      Successfully uninstalled jaxlib-0.7.2\n",
            "  Attempting uninstall: jax\n",
            "    Found existing installation: jax 0.7.2\n",
            "    Uninstalling jax-0.7.2:\n",
            "      Successfully uninstalled jax-0.7.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.8 which is incompatible.\n",
            "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opentelemetry-proto 1.37.0 requires protobuf<7.0,>=5.0, but you have protobuf 4.25.8 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "ydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 4.25.8 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed jax-0.7.1 jaxlib-0.7.1 mediapipe-0.10.21 numpy-1.26.4 opencv-contrib-python-4.11.0.86 protobuf-4.25.8 sounddevice-0.5.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "numpy"
                ]
              },
              "id": "0fd3f567fd5646d69e525a0b5fbdcbc9"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install mediapipe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewIzrSdCtoeg"
      },
      "source": [
        "### Helper Func"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bXoyRvJQtoeh"
      },
      "outputs": [],
      "source": [
        "def calculate_angle(a, b, c):\n",
        "    \"\"\"\n",
        "    세 개의 랜드마크(a, b, c)를 받아 b 지점의 각도와 신뢰도(가시성 곱)를 반환합니다.\n",
        "    \"\"\"\n",
        "    reliability = a[3] * b[3] * c[3]\n",
        "\n",
        "    if a[3] < 0.5 or b[3] < 0.5 or c[3] < 0.5:\n",
        "        return None, reliability\n",
        "\n",
        "    a_xyz = a[:3]\n",
        "    b_xyz = b[:3]\n",
        "    c_xyz = c[:3]\n",
        "\n",
        "    try:\n",
        "        ba = a_xyz - b_xyz\n",
        "        bc = c_xyz - b_xyz\n",
        "\n",
        "        cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))\n",
        "        cosine_angle = np.clip(cosine_angle, -1.0, 1.0)\n",
        "        angle = np.arccos(cosine_angle)\n",
        "\n",
        "        return np.degrees(angle), reliability\n",
        "    except (ZeroDivisionError, RuntimeWarning):\n",
        "        return None, reliability\n",
        "\n",
        "def calculate_plane_normal(a, b, c):\n",
        "    \"\"\"\n",
        "    세 개의 랜드마크(a, b, c)로 정의된 평면의 법선 벡터(Normal Vector)를 반환합니다.\n",
        "    반환값: [x, y, z] (정규화된 벡터), reliability\n",
        "    순서는 a -> b -> c 순으로 오른손 법칙을 따릅니다.\n",
        "    \"\"\"\n",
        "    # 신뢰도 계산\n",
        "    reliability = a[3] * b[3] * c[3]\n",
        "\n",
        "    # 가시성이 낮은 랜드마크가 포함되면 계산 불가\n",
        "    if a[3] < 0.5 or b[3] < 0.5 or c[3] < 0.5:\n",
        "        return None, reliability\n",
        "\n",
        "    a_xyz = a[:3]\n",
        "    b_xyz = b[:3]\n",
        "    c_xyz = c[:3]\n",
        "\n",
        "    try:\n",
        "        # 두 개의 벡터 생성 (a -> b, a -> c)\n",
        "        v1 = b_xyz - a_xyz\n",
        "        v2 = c_xyz - a_xyz\n",
        "\n",
        "        # 외적(Cross Product)을 통해 법선 벡터 계산\n",
        "        normal = np.cross(v1, v2)\n",
        "\n",
        "        # 벡터 정규화 (크기를 1로 만듦)\n",
        "        norm_length = np.linalg.norm(normal)\n",
        "        if norm_length == 0:\n",
        "            return None, reliability\n",
        "\n",
        "        normalized_normal = normal / norm_length\n",
        "\n",
        "        return normalized_normal, reliability\n",
        "\n",
        "    except (RuntimeWarning, Exception):\n",
        "        return None, reliability\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjRAbBUKtoel"
      },
      "source": [
        "## Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wRzhgFTUtoep"
      },
      "outputs": [],
      "source": [
        "def feature_engineering(landmarks):\n",
        "    \"\"\"\n",
        "    landmarks: (33, 4) shape의 numpy array [x, y, z, visibility]\n",
        "    \"\"\"\n",
        "    if landmarks is None: return None\n",
        "    NOSE = 0\n",
        "    L_EYE, R_EYE = 2, 5\n",
        "    L_EAR, R_EAR = 7, 8\n",
        "    L_SHOULDER, R_SHOULDER = 11, 12\n",
        "    L_ELBOW, R_ELBOW = 13, 14\n",
        "    L_WRIST, R_WRIST = 15, 16\n",
        "    L_HIP, R_HIP = 23, 24\n",
        "\n",
        "    normal_features, normal_rels = [], []\n",
        "\n",
        "    face_normal, face_rel = calculate_plane_normal(landmarks[NOSE], landmarks[L_EYE], landmarks[R_EYE])\n",
        "    normal_features.append(face_normal)\n",
        "    normal_rels.append(face_rel)\n",
        "\n",
        "    sh_nose_normal, sh_nose_rel = calculate_plane_normal(landmarks[L_SHOULDER], landmarks[R_SHOULDER], landmarks[NOSE])\n",
        "    normal_features.append(sh_nose_normal)\n",
        "    normal_rels.append(sh_nose_rel)\n",
        "\n",
        "    flat_normals_vec = []\n",
        "    for vec in normal_features:\n",
        "        if vec is not None: flat_normals_vec.extend(vec)\n",
        "        else: flat_normals_vec.extend([0.0, 0.0, 0.0])\n",
        "\n",
        "    final_features = flat_normals_vec + normal_rels\n",
        "    return np.array(final_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nA508CHTtoeq"
      },
      "source": [
        "## MLP(val_accuracy = 0.8915)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NOVr50REq-KD",
        "outputId": "eaef55ef-29a8-4dfe-f829-f56f1dc23e47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'X_train.npy'와 'Y_train.npy'에서 데이터셋 로드 중...\n",
            "로드 완료. 랜드마크: (2139, 33, 4), 레이블: (2139,)\n",
            "\n",
            "특징 공학(Feature Engineering) 적용 중...\n",
            "학습 데이터: 2139개 / 테스트 데이터: 250개\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m576\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,689\u001b[0m (10.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,689</span> (10.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,689\u001b[0m (10.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,689</span> (10.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "모델 학습 시작...\n",
            "Epoch 1/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6280 - loss: 0.6517 - val_accuracy: 0.5189 - val_loss: 0.6739\n",
            "Epoch 2/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6707 - loss: 0.5905 - val_accuracy: 0.5377 - val_loss: 0.6079\n",
            "Epoch 3/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6835 - loss: 0.5297 - val_accuracy: 0.6557 - val_loss: 0.5413\n",
            "Epoch 4/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7495 - loss: 0.4608 - val_accuracy: 0.6274 - val_loss: 0.5211\n",
            "Epoch 5/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7804 - loss: 0.4256 - val_accuracy: 0.7972 - val_loss: 0.4269\n",
            "Epoch 6/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8265 - loss: 0.3839 - val_accuracy: 0.7877 - val_loss: 0.4154\n",
            "Epoch 7/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8525 - loss: 0.3519 - val_accuracy: 0.8726 - val_loss: 0.3437\n",
            "Epoch 8/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8630 - loss: 0.3184 - val_accuracy: 0.8726 - val_loss: 0.3262\n",
            "Epoch 9/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8922 - loss: 0.2870 - val_accuracy: 0.7877 - val_loss: 0.4137\n",
            "Epoch 10/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8840 - loss: 0.2852 - val_accuracy: 0.8113 - val_loss: 0.3745\n",
            "Epoch 11/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8735 - loss: 0.2901 - val_accuracy: 0.8679 - val_loss: 0.2955\n",
            "Epoch 12/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8878 - loss: 0.2611 - val_accuracy: 0.9057 - val_loss: 0.2688\n",
            "Epoch 13/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8789 - loss: 0.2811 - val_accuracy: 0.8349 - val_loss: 0.3380\n",
            "Epoch 14/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9041 - loss: 0.2513 - val_accuracy: 0.6651 - val_loss: 0.5670\n",
            "Epoch 15/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8939 - loss: 0.2570 - val_accuracy: 0.9292 - val_loss: 0.2138\n",
            "Epoch 16/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8907 - loss: 0.2514 - val_accuracy: 0.8726 - val_loss: 0.3068\n",
            "Epoch 17/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8957 - loss: 0.2553 - val_accuracy: 0.9292 - val_loss: 0.2247\n",
            "Epoch 18/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9096 - loss: 0.2296 - val_accuracy: 0.8915 - val_loss: 0.2597\n",
            "Epoch 19/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8930 - loss: 0.2494 - val_accuracy: 0.8302 - val_loss: 0.3637\n",
            "Epoch 20/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9009 - loss: 0.2386 - val_accuracy: 0.8019 - val_loss: 0.4471\n",
            "Epoch 21/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9211 - loss: 0.2136 - val_accuracy: 0.7642 - val_loss: 0.4612\n",
            "Epoch 22/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8975 - loss: 0.2449 - val_accuracy: 0.6085 - val_loss: 0.8909\n",
            "Epoch 23/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9055 - loss: 0.2301 - val_accuracy: 0.8821 - val_loss: 0.2772\n",
            "Epoch 24/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9003 - loss: 0.2268 - val_accuracy: 0.8821 - val_loss: 0.2770\n",
            "Epoch 25/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9095 - loss: 0.2264 - val_accuracy: 0.7642 - val_loss: 0.5065\n",
            "Epoch 26/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9110 - loss: 0.2285 - val_accuracy: 0.6698 - val_loss: 0.6244\n",
            "Epoch 27/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9177 - loss: 0.2151 - val_accuracy: 0.8255 - val_loss: 0.3847\n",
            "Epoch 28/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9106 - loss: 0.2252 - val_accuracy: 0.8208 - val_loss: 0.4127\n",
            "Epoch 29/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9061 - loss: 0.2261 - val_accuracy: 0.8821 - val_loss: 0.2719\n",
            "Epoch 30/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9134 - loss: 0.2254 - val_accuracy: 0.6840 - val_loss: 0.5790\n",
            "Epoch 31/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8953 - loss: 0.2367 - val_accuracy: 0.6415 - val_loss: 0.6708\n",
            "Epoch 32/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9026 - loss: 0.2301 - val_accuracy: 0.6368 - val_loss: 0.7110\n",
            "Epoch 33/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9010 - loss: 0.2255 - val_accuracy: 0.8726 - val_loss: 0.2933\n",
            "Epoch 34/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9146 - loss: 0.2039 - val_accuracy: 0.6934 - val_loss: 0.5861\n",
            "Epoch 35/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8999 - loss: 0.2349 - val_accuracy: 0.8915 - val_loss: 0.2632\n",
            "모델 학습 완료.\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7990 - loss: 0.3493 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "테스트 데이터 평가 결과:\n",
            "Loss (손실): 0.7231\n",
            "Accuracy (정확도): 0.5520\n",
            "학습된 모델을 'pose_classifier_keras.h5'로 저장했습니다.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Input\n",
        "\n",
        "def build_model(input_shape):\n",
        "    \"\"\"\n",
        "    특징 벡터를 입력받는 Keras 분류 모델을 구성합니다.\n",
        "    \"\"\"\n",
        "    model = Sequential([\n",
        "        Input(shape=(input_shape,)),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dropout(0.3),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dropout(0.3),\n",
        "        # 이진 분류를 위한 Sigmoid 활성화 함수\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=[tf.keras.metrics.BinaryAccuracy(name='accuracy')])\n",
        "    return model\n",
        "\n",
        "# --- 메인 실행 로직 ---\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # --- 1. 데이터 로드 ---\n",
        "    # .npy 파일 경로\n",
        "    X_DATA_PATH = 'X_train.npy'\n",
        "    Y_DATA_PATH = 'Y_train.npy'\n",
        "    X_VAL_PATH = 'X_val.npy'\n",
        "    Y_VAL_PATH = 'Y_val.npy'\n",
        "    X_TEST_PATH = 'X_test.npy'\n",
        "    Y_TEST_PATH = 'Y_test.npy'\n",
        "\n",
        "    print(f\"'{X_DATA_PATH}'와 '{Y_DATA_PATH}'에서 데이터셋 로드 중...\")\n",
        "\n",
        "    if not os.path.exists(X_DATA_PATH) or not os.path.exists(Y_DATA_PATH):\n",
        "        print(\"=\"*50)\n",
        "        print(f\"오류: '{X_DATA_PATH}' 또는 '{Y_DATA_PATH}' 파일을 찾을 수 없습니다.\")\n",
        "        print(\"데이터셋 파일이 스크립트와 동일한 디렉토리에 있는지 확인해주세요.\")\n",
        "        print(\"=\"*50)\n",
        "    else:\n",
        "        try:\n",
        "            # .npy 파일에서 각각 랜드마크와 레이블을 불러옵니다.\n",
        "            raw_landmarks = np.load(X_DATA_PATH)\n",
        "            raw_val = np.load(X_VAL_PATH)\n",
        "            raw_test = np.load(X_TEST_PATH)\n",
        "            labels = np.load(Y_DATA_PATH)\n",
        "            labels_val = np.load(Y_VAL_PATH)\n",
        "            labels_test = np.load(Y_TEST_PATH)\n",
        "            print(f\"로드 완료. 랜드마크: {raw_landmarks.shape}, 레이블: {labels.shape}\")\n",
        "\n",
        "            if raw_landmarks.shape[0] == 0:\n",
        "                print(\"오류: 로드된 데이터셋이 비어있습니다.\")\n",
        "            else:\n",
        "                # --- 2. 특징 공학 (Feature Engineering) ---\n",
        "\n",
        "                print(\"\\n특징 공학(Feature Engineering) 적용 중...\")\n",
        "                features = []\n",
        "                valid_labels = []\n",
        "\n",
        "                for i, lm in enumerate(raw_landmarks):\n",
        "                    feature_vector = feature_engineering(lm)\n",
        "                    # 특징 추출에 성공한(None이 아닌) 샘플만 사용\n",
        "                    if feature_vector is not None:\n",
        "                        features.append(feature_vector)\n",
        "                        valid_labels.append(labels[i])\n",
        "                features_val = []\n",
        "                valid_labels_val = []\n",
        "\n",
        "                for i, lm in enumerate(raw_val):\n",
        "                    feature_vector = feature_engineering(lm)\n",
        "                    # 특징 추출에 성공한(None이 아닌) 샘플만 사용\n",
        "                    if feature_vector is not None:\n",
        "                        features_val.append(feature_vector)\n",
        "                        valid_labels_val.append(labels_val[i])\n",
        "\n",
        "                features_test = []\n",
        "                valid_labels_test = []\n",
        "\n",
        "                for i, lm in enumerate(raw_test):\n",
        "                    feature_vector = feature_engineering(lm)\n",
        "                    # 특징 추출에 성공한(None이 아닌) 샘플만 사용\n",
        "                    if feature_vector is not None:\n",
        "                        features_test.append(feature_vector)\n",
        "                        valid_labels_test.append(labels_test[i])\n",
        "\n",
        "                # X: (n_valid_samples, n_features)\n",
        "                # y: (n_valid_samples,)\n",
        "                X_train = np.array(features)\n",
        "                y_train = np.array(valid_labels)\n",
        "                X_val = np.array(features_val)\n",
        "                y_val = np.array(valid_labels_val)\n",
        "                X_test = np.array(features_test)\n",
        "                y_test = np.array(valid_labels_test)\n",
        "\n",
        "                if X_train.shape[0] == 0:\n",
        "                     print(\"오류: 모든 샘플에서 특징 공학(각도 계산 등)에 실패했습니다.\")\n",
        "                     print(\"데이터셋의 가시성(visibility) 값을 확인해주세요.\")\n",
        "                else:\n",
        "\n",
        "                    print(f\"학습 데이터: {X_train.shape[0]}개 / 테스트 데이터: {X_test.shape[0]}개\")\n",
        "\n",
        "                    # --- 4. 모델 학습 ---\n",
        "                    # 1. 인덱스 배열 생성 (0부터 N-1까지)\n",
        "                    indices = np.arange(X_train.shape[0])\n",
        "\n",
        "                    # 2. 인덱스 무작위 섞기\n",
        "                    np.random.shuffle(indices)\n",
        "\n",
        "                    # 3. 섞인 인덱스로 X와 y 재배열 (짝 유지됨)\n",
        "                    X_train = X_train[indices]\n",
        "                    y_train = y_train[indices]\n",
        "\n",
        "                    # 입력 차원(input_shape)은 특징 벡터의 크기입니다. (여기서는 8)\n",
        "                    model = build_model(input_shape=X_train.shape[1])\n",
        "                    model.summary()\n",
        "\n",
        "                    print(\"\\n모델 학습 시작...\")\n",
        "                    history = model.fit(\n",
        "                        X_train,\n",
        "                        y_train,\n",
        "                        epochs=500,\n",
        "                        batch_size=16,\n",
        "                        validation_data=(X_val, y_val),\n",
        "                        callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)]\n",
        "                    )\n",
        "\n",
        "                    print(\"모델 학습 완료.\")\n",
        "\n",
        "                    # --- 5. 모델 평가 ---\n",
        "                    loss, accuracy = model.evaluate(X_test, y_test)\n",
        "                    print(f\"\\n테스트 데이터 평가 결과:\")\n",
        "                    print(f\"Loss (손실): {loss:.4f}\")\n",
        "                    print(f\"Accuracy (정확도): {accuracy:.4f}\")\n",
        "\n",
        "                    # --- 6. 모델 저장 ---\n",
        "                    model.save(\"plane_pose_classifier_keras.h5\")\n",
        "                    print(\"학습된 모델을 'plane_pose_classifier_keras.h5'로 저장했습니다.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"오류: 데이터셋 로드 또는 처리 중 예외 발생: {e}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Dkuzqwvtoev"
      },
      "source": [
        "## RandomForest (val_accuracy = 0.8688)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "stotQbNEf7cP",
        "outputId": "cc005a56-f7f4-4af6-b8a2-a548616a3e2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "데이터 전처리 중...\n",
            "데이터 셔플링 중...\n",
            "\n",
            "[Random Forest] 학습 시작 (데이터 개수: 2139개)...\n",
            "학습 완료.\n",
            "\n",
            "테스트 데이터 평가 결과:\n",
            "Accuracy (정확도): 0.8868\n",
            "\n",
            "분류 보고서:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.97      0.90       110\n",
            "           1       0.96      0.79      0.87       102\n",
            "\n",
            "    accuracy                           0.89       212\n",
            "   macro avg       0.90      0.88      0.89       212\n",
            "weighted avg       0.90      0.89      0.89       212\n",
            "\n",
            "모델 저장 완료: 'pose_classifier_rf.pkl'\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import joblib  # scikit-learn 모델 저장용\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# --- 메인 실행 로직 ---\n",
        "if __name__ == \"__main__\":\n",
        "    X_DATA_PATH = 'X_train.npy'; Y_DATA_PATH = 'Y_train.npy'\n",
        "    X_TEST_PATH = 'X_val.npy'; Y_TEST_PATH = 'Y_val.npy'\n",
        "\n",
        "    if not os.path.exists(X_DATA_PATH):\n",
        "        print(\"데이터 파일 없음\"); exit()\n",
        "\n",
        "    try:\n",
        "        raw_landmarks = np.load(X_DATA_PATH)\n",
        "        labels = np.load(Y_DATA_PATH)\n",
        "        raw_test = np.load(X_TEST_PATH)\n",
        "        labels_test = np.load(Y_TEST_PATH)\n",
        "\n",
        "        # 데이터 처리 함수\n",
        "        def process_data(raw_x, raw_y):\n",
        "            processed_x, processed_y = [], []\n",
        "            for i, lm in enumerate(raw_x):\n",
        "                fv = feature_engineering(lm)\n",
        "                if fv is not None:\n",
        "                    processed_x.append(fv)\n",
        "                    processed_y.append(raw_y[i])\n",
        "            return np.array(processed_x), np.array(processed_y)\n",
        "\n",
        "        print(\"데이터 전처리 중...\")\n",
        "        X_train, y_train = process_data(raw_landmarks, labels)\n",
        "        X_test, y_test = process_data(raw_test, labels_test)\n",
        "\n",
        "        # --- 셔플링 (Shuffling) ---\n",
        "        print(\"데이터 셔플링 중...\")\n",
        "        indices = np.arange(X_train.shape[0])\n",
        "        np.random.shuffle(indices)\n",
        "        X_train = X_train[indices]\n",
        "        y_train = y_train[indices]\n",
        "\n",
        "        # --- Random Forest 모델 학습 ---\n",
        "        print(f\"\\n[Random Forest] 학습 시작 (데이터 개수: {len(X_train)}개)...\")\n",
        "        # n_estimators: 트리의 개수 (보통 100~500)\n",
        "        rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "        rf_model.fit(X_train, y_train)\n",
        "        print(\"학습 완료.\")\n",
        "\n",
        "        # --- 모델 평가 ---\n",
        "        y_pred = rf_model.predict(X_test)\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "        print(f\"\\n테스트 데이터 평가 결과:\")\n",
        "        print(f\"Accuracy (정확도): {accuracy:.4f}\")\n",
        "        print(\"\\n분류 보고서:\")\n",
        "        print(classification_report(y_test, y_pred))\n",
        "\n",
        "        # --- 모델 저장 ---\n",
        "        joblib.dump(rf_model, \"plane_pose_classifier_rf.pkl\")\n",
        "        print(\"모델 저장 완료: 'plane_pose_classifier_rf.pkl'\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"오류 발생: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itZJbt5_toe1"
      },
      "source": [
        "## Support Vector Machine (val_accuracy = 0.9210)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqFSiCEcgOkM",
        "outputId": "9b821037-4483-4ad9-e2dd-6ea748db5ba7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "데이터 전처리 중 (신뢰도 포함)...\n",
            "특징 벡터 차원: 8 (예상: 6+9+6+2 = 23 또는 유사)\n",
            "데이터 셔플링 중...\n",
            "\n",
            "[SVM] 학습 준비 (데이터 개수: 2139개)...\n",
            "교차 검증(Cross Validation) 진행 중...\n",
            " >> 5-Fold 검증 정확도: [0.93457944 0.90654206 0.92757009 0.9135514  0.92271663]\n",
            " >> 평균 검증 정확도: 0.9210\n",
            "최종 모델 학습 중...\n",
            "\n",
            "테스트 데이터 평가 결과:\n",
            "Accuracy (정확도): 0.4680\n",
            "\n",
            "분류 보고서:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       133\n",
            "           1       0.47      1.00      0.64       117\n",
            "\n",
            "    accuracy                           0.47       250\n",
            "   macro avg       0.23      0.50      0.32       250\n",
            "weighted avg       0.22      0.47      0.30       250\n",
            "\n",
            "모델 저장 완료: 'pose_classifier_svm.pkl'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import joblib\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "\n",
        "# --- 메인 실행 로직 ---\n",
        "if __name__ == \"__main__\":\n",
        "    X_DATA_PATH = 'X_train.npy'; Y_DATA_PATH = 'Y_train.npy'\n",
        "    X_TEST_PATH = 'X_test.npy'; Y_TEST_PATH = 'Y_test.npy'\n",
        "\n",
        "    if not os.path.exists(X_DATA_PATH):\n",
        "        print(\"데이터 파일 없음\"); exit()\n",
        "\n",
        "    try:\n",
        "        raw_landmarks = np.load(X_DATA_PATH)\n",
        "        labels = np.load(Y_DATA_PATH)\n",
        "        raw_test = np.load(X_TEST_PATH)\n",
        "        labels_test = np.load(Y_TEST_PATH)\n",
        "\n",
        "        def process_data(raw_x, raw_y):\n",
        "            processed_x, processed_y = [], []\n",
        "            for i, lm in enumerate(raw_x):\n",
        "                fv = feature_engineering(lm)\n",
        "                if fv is not None:\n",
        "                    processed_x.append(fv)\n",
        "                    processed_y.append(raw_y[i])\n",
        "            return np.array(processed_x), np.array(processed_y)\n",
        "\n",
        "        print(\"데이터 전처리 중 (신뢰도 포함)...\")\n",
        "        X_train, y_train = process_data(raw_landmarks, labels)\n",
        "        X_test, y_test = process_data(raw_test, labels_test)\n",
        "\n",
        "        print(f\"특징 벡터 차원: {X_train.shape[1]} (예상: 6+9+6+2 = 23 또는 유사)\")\n",
        "\n",
        "        # --- 셔플링 (Shuffling) ---\n",
        "        print(\"데이터 셔플링 중...\")\n",
        "        indices = np.arange(X_train.shape[0])\n",
        "        np.random.shuffle(indices)\n",
        "        X_train = X_train[indices]\n",
        "        y_train = y_train[indices]\n",
        "\n",
        "        # --- SVM 모델 정의 ---\n",
        "        print(f\"\\n[SVM] 학습 준비 (데이터 개수: {len(X_train)}개)...\")\n",
        "\n",
        "        # SVM 파이프라인 (스케일링 + SVM)\n",
        "        svm_model = make_pipeline(\n",
        "            StandardScaler(),\n",
        "            SVC(kernel='rbf', C=1.0, probability=True, random_state=42)\n",
        "        )\n",
        "\n",
        "        # --- 1. 교차 검증 (Validation) ---\n",
        "        print(\"교차 검증(Cross Validation) 진행 중...\")\n",
        "        val_scores = cross_val_score(svm_model, X_train, y_train, cv=5)\n",
        "        print(f\" >> 5-Fold 검증 정확도: {val_scores}\")\n",
        "        print(f\" >> 평균 검증 정확도: {np.mean(val_scores):.4f}\")\n",
        "\n",
        "        # --- 2. 전체 데이터로 최종 학습 ---\n",
        "        print(\"최종 모델 학습 중...\")\n",
        "        svm_model.fit(X_train, y_train)\n",
        "\n",
        "        # --- 모델 평가 ---\n",
        "        y_pred = svm_model.predict(X_test)\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "        print(f\"\\n테스트 데이터 평가 결과:\")\n",
        "        print(f\"Accuracy (정확도): {accuracy:.4f}\")\n",
        "        print(\"\\n분류 보고서:\")\n",
        "        print(classification_report(y_test, y_pred))\n",
        "\n",
        "        # --- 모델 저장 ---\n",
        "        joblib.dump(svm_model, \"plane_pose_classifier_svm.pkl\")\n",
        "        print(\"모델 저장 완료: 'plane_pose_classifier_svm.pkl'\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"오류 발생: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3jBv-xCtoe2"
      },
      "source": [
        "## Log_Regression(val_accuracy = 0.5708)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdNdfX0itoe3",
        "outputId": "370f115b-d6f0-471c-ea86-26e83af25f9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 모델 학습 및 환경 준비 완료\n",
            "\n",
            "--- 🧪 모델 검증 결과 (Test Set) ---\n",
            "✅ 정확도: 57.08%\n",
            "\n",
            "[ 혼동 행렬 (Confusion Matrix) ]\n",
            "[[84 26]\n",
            " [65 37]]\n",
            "\n",
            "[ 분류 리포트 (Classification Report) ]\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            " Bad Posture (0)       0.56      0.76      0.65       110\n",
            "Good Posture (1)       0.59      0.36      0.45       102\n",
            "\n",
            "        accuracy                           0.57       212\n",
            "       macro avg       0.58      0.56      0.55       212\n",
            "    weighted avg       0.58      0.57      0.55       212\n",
            "\n",
            "-----------------------------------\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        "import mediapipe as mp\n",
        "import cv2\n",
        "\n",
        "X_TRAIN_PATH = 'X_train.npy'\n",
        "Y_TRAIN_PATH = 'Y_train.npy'\n",
        "X_TEST_PATH = 'X_val.npy'\n",
        "Y_TEST_PATH = 'Y_val.npy'\n",
        "\n",
        "raw_landmarks = np.load(X_TRAIN_PATH)\n",
        "labels = np.load(Y_TRAIN_PATH)\n",
        "test_landmarks = np.load(X_TEST_PATH)\n",
        "test_labels = np.load(Y_TEST_PATH)\n",
        "\n",
        "features = []\n",
        "valid_labels = []\n",
        "test_features = []\n",
        "testlabels = []\n",
        "\n",
        "for i, lm in enumerate(raw_landmarks):\n",
        "    feature_vector = feature_engineering(lm)\n",
        "    # 특징 추출에 성공한(None이 아닌) 샘플만 사용\n",
        "    if feature_vector is not None:\n",
        "        features.append(feature_vector)\n",
        "        valid_labels.append(labels[i])\n",
        "\n",
        "for i, lm in enumerate(test_landmarks):\n",
        "    feature_vector = feature_engineering(lm)\n",
        "    # 특징 추출에 성공한(None이 아닌) 샘플만 사용\n",
        "    if feature_vector is not None:\n",
        "        test_features.append(feature_vector)\n",
        "        testlabels.append(test_labels[i])\n",
        "\n",
        "X_train = np.array(features)\n",
        "Y_train = np.array(valid_labels)\n",
        "\n",
        "X_test = np.array(test_features)\n",
        "Y_test = np.array(testlabels)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "log_reg_model = LogisticRegression(solver='liblinear', random_state=42)\n",
        "log_reg_model.fit(X_train_scaled, Y_train)\n",
        "\n",
        "print(\"✅ 모델 학습 및 환경 준비 완료\")\n",
        "\n",
        "# --- 2. [추가] 모델 검증 코드 ---\n",
        "print(\"\\n--- 🧪 모델 검증 결과 (Test Set) ---\")\n",
        "Y_pred = log_reg_model.predict(X_test_scaled)\n",
        "\n",
        "# 정확도 (Accuracy)\n",
        "accuracy = accuracy_score(Y_test, Y_pred)\n",
        "print(f\"✅ 정확도: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# 혼동 행렬 (Confusion Matrix)\n",
        "print(\"\\n[ 혼동 행렬 (Confusion Matrix) ]\")\n",
        "print(confusion_matrix(Y_test, Y_pred))\n",
        "\n",
        "# 분류 리포트 (Precision, Recall, F1-score)\n",
        "# target_names는 0번 클래스와 1번 클래스의 이름을 지정합니다.\n",
        "print(\"\\n[ 분류 리포트 (Classification Report) ]\")\n",
        "print(classification_report(Y_test, Y_pred, target_names=['Bad Posture (0)', 'Good Posture (1)']))\n",
        "print(\"-----------------------------------\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python (motion_transformer)",
      "language": "python",
      "name": "motion_transformer"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.23"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}