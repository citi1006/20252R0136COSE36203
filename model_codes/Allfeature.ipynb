{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tR9ECn3QtoeY"
      },
      "source": [
        "### Install Mediapipe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ipKyFljfvoTk",
        "outputId": "c46ce667-085b-4931-edc3-a6303e8549c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mediapipe\n",
            "  Downloading mediapipe-0.10.21-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.12/dist-packages (from mediapipe) (25.4.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.12/dist-packages (from mediapipe) (25.9.23)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.12/dist-packages (from mediapipe) (0.7.2)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.12/dist-packages (from mediapipe) (0.7.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from mediapipe) (3.10.0)\n",
            "Collecting numpy<2 (from mediapipe)\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.12/dist-packages (from mediapipe) (4.12.0.88)\n",
            "Collecting protobuf<5,>=4.25.3 (from mediapipe)\n",
            "  Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Collecting sounddevice>=0.4.4 (from mediapipe)\n",
            "  Downloading sounddevice-0.5.3-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from mediapipe) (0.2.1)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.12/dist-packages (from sounddevice>=0.4.4->mediapipe) (2.0.0)\n",
            "Requirement already satisfied: ml_dtypes>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from jax->mediapipe) (0.5.4)\n",
            "INFO: pip is looking at multiple versions of jax to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting jax (from mediapipe)\n",
            "  Downloading jax-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting jaxlib (from mediapipe)\n",
            "  Downloading jaxlib-0.8.1-cp312-cp312-manylinux_2_27_x86_64.whl.metadata (1.3 kB)\n",
            "Collecting jax (from mediapipe)\n",
            "  Downloading jax-0.8.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting jaxlib (from mediapipe)\n",
            "  Downloading jaxlib-0.8.0-cp312-cp312-manylinux_2_27_x86_64.whl.metadata (1.3 kB)\n",
            "Collecting jax (from mediapipe)\n",
            "  Downloading jax-0.7.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting jaxlib (from mediapipe)\n",
            "  Downloading jaxlib-0.7.1-cp312-cp312-manylinux_2_27_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.12/dist-packages (from jax->mediapipe) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.12 in /usr/local/lib/python3.12/dist-packages (from jax->mediapipe) (1.16.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (4.61.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
            "INFO: pip is looking at multiple versions of opencv-contrib-python to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting opencv-contrib-python (from mediapipe)\n",
            "  Downloading opencv_contrib_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.23)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\n",
            "Downloading mediapipe-0.10.21-cp312-cp312-manylinux_2_28_x86_64.whl (35.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.6/35.6 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sounddevice-0.5.3-py3-none-any.whl (32 kB)\n",
            "Downloading jax-0.7.1-py3-none-any.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jaxlib-0.7.1-cp312-cp312-manylinux_2_27_x86_64.whl (81.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.2/81.2 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_contrib_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (69.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: protobuf, numpy, sounddevice, opencv-contrib-python, jaxlib, jax, mediapipe\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.5\n",
            "    Uninstalling protobuf-5.29.5:\n",
            "      Successfully uninstalled protobuf-5.29.5\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: opencv-contrib-python\n",
            "    Found existing installation: opencv-contrib-python 4.12.0.88\n",
            "    Uninstalling opencv-contrib-python-4.12.0.88:\n",
            "      Successfully uninstalled opencv-contrib-python-4.12.0.88\n",
            "  Attempting uninstall: jaxlib\n",
            "    Found existing installation: jaxlib 0.7.2\n",
            "    Uninstalling jaxlib-0.7.2:\n",
            "      Successfully uninstalled jaxlib-0.7.2\n",
            "  Attempting uninstall: jax\n",
            "    Found existing installation: jax 0.7.2\n",
            "    Uninstalling jax-0.7.2:\n",
            "      Successfully uninstalled jax-0.7.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.8 which is incompatible.\n",
            "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opentelemetry-proto 1.37.0 requires protobuf<7.0,>=5.0, but you have protobuf 4.25.8 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "ydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 4.25.8 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed jax-0.7.1 jaxlib-0.7.1 mediapipe-0.10.21 numpy-1.26.4 opencv-contrib-python-4.11.0.86 protobuf-4.25.8 sounddevice-0.5.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "numpy"
                ]
              },
              "id": "0fd3f567fd5646d69e525a0b5fbdcbc9"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install mediapipe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewIzrSdCtoeg"
      },
      "source": [
        "### Helper Func"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bXoyRvJQtoeh"
      },
      "outputs": [],
      "source": [
        "def calculate_angle(a, b, c):\n",
        "    \"\"\"\n",
        "    세 개의 랜드마크(a, b, c)를 받아 b 지점의 각도와 신뢰도(가시성 곱)를 반환합니다.\n",
        "    \"\"\"\n",
        "    reliability = a[3] * b[3] * c[3]\n",
        "\n",
        "    if a[3] < 0.5 or b[3] < 0.5 or c[3] < 0.5:\n",
        "        return None, reliability\n",
        "\n",
        "    a_xyz = a[:3]\n",
        "    b_xyz = b[:3]\n",
        "    c_xyz = c[:3]\n",
        "\n",
        "    try:\n",
        "        ba = a_xyz - b_xyz\n",
        "        bc = c_xyz - b_xyz\n",
        "\n",
        "        cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))\n",
        "        cosine_angle = np.clip(cosine_angle, -1.0, 1.0)\n",
        "        angle = np.arccos(cosine_angle)\n",
        "\n",
        "        return np.degrees(angle), reliability\n",
        "    except (ZeroDivisionError, RuntimeWarning):\n",
        "        return None, reliability\n",
        "\n",
        "def calculate_plane_normal(a, b, c):\n",
        "    \"\"\"\n",
        "    세 개의 랜드마크(a, b, c)로 정의된 평면의 법선 벡터(Normal Vector)를 반환합니다.\n",
        "    반환값: [x, y, z] (정규화된 벡터), reliability\n",
        "    순서는 a -> b -> c 순으로 오른손 법칙을 따릅니다.\n",
        "    \"\"\"\n",
        "    # 신뢰도 계산\n",
        "    reliability = a[3] * b[3] * c[3]\n",
        "\n",
        "    # 가시성이 낮은 랜드마크가 포함되면 계산 불가\n",
        "    if a[3] < 0.5 or b[3] < 0.5 or c[3] < 0.5:\n",
        "        return None, reliability\n",
        "\n",
        "    a_xyz = a[:3]\n",
        "    b_xyz = b[:3]\n",
        "    c_xyz = c[:3]\n",
        "\n",
        "    try:\n",
        "        # 두 개의 벡터 생성 (a -> b, a -> c)\n",
        "        v1 = b_xyz - a_xyz\n",
        "        v2 = c_xyz - a_xyz\n",
        "\n",
        "        # 외적(Cross Product)을 통해 법선 벡터 계산\n",
        "        normal = np.cross(v1, v2)\n",
        "\n",
        "        # 벡터 정규화 (크기를 1로 만듦)\n",
        "        norm_length = np.linalg.norm(normal)\n",
        "        if norm_length == 0:\n",
        "            return None, reliability\n",
        "\n",
        "        normalized_normal = normal / norm_length\n",
        "\n",
        "        return normalized_normal, reliability\n",
        "\n",
        "    except (RuntimeWarning, Exception):\n",
        "        return None, reliability\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjRAbBUKtoel"
      },
      "source": [
        "## Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "wRzhgFTUtoep"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# 헬퍼 함수들은 외부에 정의되어 있다고 가정 (calculate_angle, calculate_plane_normal)\n",
        "# 만약 없다면 맨 처음 드린 코드의 헬퍼 함수를 그대로 쓰시면 됩니다.\n",
        "\n",
        "def feature_engineering(landmarks):\n",
        "    \"\"\"\n",
        "    [Hybrid Feature Engineering]\n",
        "    1. Raw 좌표: 어깨 중심 + 어깨 너비 정규화 (Scale Invariant)\n",
        "    2. 기하학적 특징: 각도(0~1 정규화) + 법선 벡터\n",
        "    3. 신뢰도 정보 포함\n",
        "\n",
        "    모든 피처의 스케일을 대략 -1~1 또는 0~1로 맞춰서 결합합니다.\n",
        "    \"\"\"\n",
        "    if landmarks is None: return None\n",
        "\n",
        "    # ==========================================\n",
        "    # 1. Raw Coordinates Processing (어깨 중심 & 크기 보정)\n",
        "    # ==========================================\n",
        "    lm_copy = landmarks.copy()\n",
        "\n",
        "    # 인덱스\n",
        "    L_SHOULDER, R_SHOULDER = 11, 12\n",
        "\n",
        "    # 기준점(Origin): 어깨 중점\n",
        "    left_sh = lm_copy[L_SHOULDER, :3]\n",
        "    right_sh = lm_copy[R_SHOULDER, :3]\n",
        "    center_point = (left_sh + right_sh) / 2.0\n",
        "\n",
        "    # 크기 기준(Scale): 어깨 너비\n",
        "    shoulder_width = np.linalg.norm(left_sh - right_sh)\n",
        "    scale_factor = shoulder_width if shoulder_width > 1e-6 else 1.0\n",
        "\n",
        "    # (A) 위치 이동 및 스케일링 -> 결과범위: 대략 -1.0 ~ 1.0\n",
        "    lm_copy[:, :3] -= center_point\n",
        "    lm_copy[:, :3] /= scale_factor\n",
        "\n",
        "    # 1차원으로 펴기 (Visibility 포함 132차원)\n",
        "    # [Tip] 만약 좌표의 visibility를 굳이 또 넣을 필요 없다면 [:, :3]만 써도 됩니다.\n",
        "    # 여기서는 정보 손실 방지를 위해 다 넣겠습니다.\n",
        "    raw_features = lm_copy.flatten()\n",
        "\n",
        "    # ==========================================\n",
        "    # 2. Geometric Features (각도 & 법선)\n",
        "    # ==========================================\n",
        "    # 인덱스 정의\n",
        "    NOSE = 0; L_EYE, R_EYE = 2, 5; L_EAR, R_EAR = 7, 8\n",
        "    L_ELBOW, R_ELBOW = 13, 14; L_WRIST, R_WRIST = 15, 16\n",
        "    L_HIP, R_HIP = 23, 24\n",
        "\n",
        "    angle_feats = []\n",
        "    normal_feats = []\n",
        "    reliability_feats = []\n",
        "\n",
        "    # (B) 각도 계산\n",
        "    angles_to_calc = [\n",
        "        (landmarks[L_SHOULDER], landmarks[L_ELBOW], landmarks[L_WRIST]),\n",
        "        (landmarks[R_SHOULDER], landmarks[R_ELBOW], landmarks[R_WRIST]),\n",
        "        (landmarks[L_ELBOW], landmarks[L_SHOULDER], landmarks[L_HIP]),\n",
        "        (landmarks[R_ELBOW], landmarks[R_SHOULDER], landmarks[R_HIP]),\n",
        "        (landmarks[L_EAR], landmarks[L_SHOULDER], landmarks[L_HIP]), # 거북목 확인용\n",
        "        (landmarks[R_EAR], landmarks[R_SHOULDER], landmarks[R_HIP])\n",
        "    ]\n",
        "\n",
        "    for p1, p2, p3 in angles_to_calc:\n",
        "        ang, rel = calculate_angle(p1, p2, p3)\n",
        "        # [중요] 각도 정규화: 0~180 -> 0.0~1.0\n",
        "        if ang is not None:\n",
        "            angle_feats.append(ang / 180.0)\n",
        "        else:\n",
        "            angle_feats.append(0.0)\n",
        "        reliability_feats.append(rel)\n",
        "\n",
        "    # (C) 법선 벡터 계산 (이미 -1~1 범위)\n",
        "    # Face Normal\n",
        "    face_norm, face_rel = calculate_plane_normal(landmarks[NOSE], landmarks[L_EYE], landmarks[R_EYE])\n",
        "    if face_norm is not None: normal_feats.extend(face_norm)\n",
        "    else: normal_feats.extend([0.0, 0.0, 0.0])\n",
        "    reliability_feats.append(face_rel)\n",
        "\n",
        "    # Chest/Shoulder Normal\n",
        "    chest_norm, chest_rel = calculate_plane_normal(landmarks[L_SHOULDER], landmarks[R_SHOULDER], landmarks[NOSE])\n",
        "    if chest_norm is not None: normal_feats.extend(chest_norm)\n",
        "    else: normal_feats.extend([0.0, 0.0, 0.0])\n",
        "    reliability_feats.append(chest_rel)\n",
        "\n",
        "    # ==========================================\n",
        "    # 3. Feature Concatenation (결합)\n",
        "    # ==========================================\n",
        "    # 리스트들을 numpy array로 변환\n",
        "    geo_vector = np.array(angle_feats + normal_feats + reliability_feats)\n",
        "\n",
        "    # [최종 결합] Raw 좌표 벡터 + 기하학적 특징 벡터\n",
        "    # 차원 수: 132 (Raw) + 6 (Angles) + 6 (Normals) + 8 (Reliability) = 152차원\n",
        "    final_features = np.concatenate([raw_features, geo_vector])\n",
        "\n",
        "    return final_features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nA508CHTtoeq"
      },
      "source": [
        "## MLP(val_accuracy = 0.9613)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NOVr50REq-KD",
        "outputId": "28d2d889-e506-4b8d-e7a5-b8ca78e75835"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'X_train.npy'와 'Y_train.npy'에서 데이터셋 로드 중...\n",
            "로드 완료. 랜드마크: (2139, 33, 4), 레이블: (2139,)\n",
            "\n",
            "특징 공학(Feature Engineering) 적용 중...\n",
            "학습 데이터: 2139개 / 테스트 데이터: 250개\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m9,792\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,792</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m11,905\u001b[0m (46.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,905</span> (46.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m11,905\u001b[0m (46.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,905</span> (46.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "모델 학습 시작...\n",
            "Epoch 1/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.6151 - loss: 0.6671 - val_accuracy: 0.8962 - val_loss: 0.4505\n",
            "Epoch 2/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6865 - loss: 0.5424 - val_accuracy: 0.9811 - val_loss: 0.2710\n",
            "Epoch 3/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7369 - loss: 0.4885 - val_accuracy: 0.9670 - val_loss: 0.2965\n",
            "Epoch 4/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7718 - loss: 0.4348 - val_accuracy: 0.9434 - val_loss: 0.2869\n",
            "Epoch 5/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7974 - loss: 0.4016 - val_accuracy: 0.9858 - val_loss: 0.1261\n",
            "Epoch 6/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8316 - loss: 0.3749 - val_accuracy: 0.9953 - val_loss: 0.1184\n",
            "Epoch 7/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8425 - loss: 0.3363 - val_accuracy: 0.5566 - val_loss: 0.6443\n",
            "Epoch 8/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8415 - loss: 0.3360 - val_accuracy: 0.9764 - val_loss: 0.1733\n",
            "Epoch 9/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8743 - loss: 0.2985 - val_accuracy: 1.0000 - val_loss: 0.0635\n",
            "Epoch 10/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8817 - loss: 0.2808 - val_accuracy: 1.0000 - val_loss: 0.0554\n",
            "Epoch 11/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8925 - loss: 0.2539 - val_accuracy: 0.9104 - val_loss: 0.2132\n",
            "Epoch 12/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8903 - loss: 0.2548 - val_accuracy: 0.9953 - val_loss: 0.0468\n",
            "Epoch 13/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8965 - loss: 0.2276 - val_accuracy: 0.9906 - val_loss: 0.1233\n",
            "Epoch 14/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9103 - loss: 0.2126 - val_accuracy: 0.7358 - val_loss: 0.4707\n",
            "Epoch 15/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9012 - loss: 0.2236 - val_accuracy: 0.9764 - val_loss: 0.0845\n",
            "Epoch 16/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8884 - loss: 0.2308 - val_accuracy: 0.9717 - val_loss: 0.1122\n",
            "Epoch 17/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9001 - loss: 0.2177 - val_accuracy: 0.9481 - val_loss: 0.1807\n",
            "Epoch 18/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9182 - loss: 0.2048 - val_accuracy: 0.9387 - val_loss: 0.1690\n",
            "Epoch 19/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9095 - loss: 0.2106 - val_accuracy: 0.9481 - val_loss: 0.1311\n",
            "Epoch 20/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9443 - loss: 0.1586 - val_accuracy: 0.9670 - val_loss: 0.1347\n",
            "Epoch 21/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9358 - loss: 0.1634 - val_accuracy: 0.9623 - val_loss: 0.1643\n",
            "Epoch 22/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9213 - loss: 0.1855 - val_accuracy: 0.9953 - val_loss: 0.0782\n",
            "Epoch 23/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9279 - loss: 0.1856 - val_accuracy: 0.6085 - val_loss: 0.8406\n",
            "Epoch 24/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9333 - loss: 0.1648 - val_accuracy: 1.0000 - val_loss: 0.0128\n",
            "Epoch 25/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9265 - loss: 0.1700 - val_accuracy: 0.9434 - val_loss: 0.1731\n",
            "Epoch 26/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9372 - loss: 0.1616 - val_accuracy: 0.9104 - val_loss: 0.2134\n",
            "Epoch 27/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9361 - loss: 0.1562 - val_accuracy: 0.9953 - val_loss: 0.0664\n",
            "Epoch 28/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9215 - loss: 0.1861 - val_accuracy: 0.9340 - val_loss: 0.1953\n",
            "Epoch 29/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9316 - loss: 0.1619 - val_accuracy: 0.7642 - val_loss: 0.5448\n",
            "Epoch 30/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9605 - loss: 0.1178 - val_accuracy: 0.5896 - val_loss: 1.3777\n",
            "Epoch 31/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9383 - loss: 0.1568 - val_accuracy: 0.8585 - val_loss: 0.4745\n",
            "Epoch 32/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9548 - loss: 0.1245 - val_accuracy: 0.9434 - val_loss: 0.1748\n",
            "Epoch 33/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9169 - loss: 0.2009 - val_accuracy: 0.8255 - val_loss: 0.5365\n",
            "Epoch 34/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9463 - loss: 0.1346 - val_accuracy: 0.8915 - val_loss: 0.3959\n",
            "Epoch 35/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9545 - loss: 0.1144 - val_accuracy: 0.9953 - val_loss: 0.0167\n",
            "Epoch 36/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9348 - loss: 0.1623 - val_accuracy: 0.9245 - val_loss: 0.2062\n",
            "Epoch 37/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9558 - loss: 0.1123 - val_accuracy: 0.6179 - val_loss: 1.0613\n",
            "Epoch 38/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9384 - loss: 0.1449 - val_accuracy: 0.8868 - val_loss: 0.2904\n",
            "Epoch 39/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9545 - loss: 0.1221 - val_accuracy: 0.9057 - val_loss: 0.2707\n",
            "Epoch 40/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9580 - loss: 0.1031 - val_accuracy: 0.7547 - val_loss: 0.5650\n",
            "Epoch 41/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9580 - loss: 0.1085 - val_accuracy: 0.6745 - val_loss: 1.0892\n",
            "Epoch 42/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9468 - loss: 0.1356 - val_accuracy: 0.9811 - val_loss: 0.0655\n",
            "Epoch 43/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9578 - loss: 0.1254 - val_accuracy: 0.6745 - val_loss: 0.7378\n",
            "Epoch 44/500\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9638 - loss: 0.0979 - val_accuracy: 0.6604 - val_loss: 0.7415\n",
            "모델 학습 완료.\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9613 - loss: 0.0842 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "테스트 데이터 평가 결과:\n",
            "Loss (손실): 0.1452\n",
            "Accuracy (정확도): 0.9200\n",
            "학습된 모델을 'All_pose_classifier_keras.h5'로 저장했습니다.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Input\n",
        "\n",
        "def build_model(input_shape):\n",
        "    \"\"\"\n",
        "    특징 벡터를 입력받는 Keras 분류 모델을 구성합니다.\n",
        "    \"\"\"\n",
        "    model = Sequential([\n",
        "        Input(shape=(input_shape,)),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dropout(0.3),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dropout(0.3),\n",
        "        # 이진 분류를 위한 Sigmoid 활성화 함수\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=[tf.keras.metrics.BinaryAccuracy(name='accuracy')])\n",
        "    return model\n",
        "\n",
        "# --- 메인 실행 로직 ---\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # --- 1. 데이터 로드 ---\n",
        "    # .npy 파일 경로\n",
        "    X_DATA_PATH = 'X_train.npy'\n",
        "    Y_DATA_PATH = 'Y_train.npy'\n",
        "    X_VAL_PATH = 'X_val.npy'\n",
        "    Y_VAL_PATH = 'Y_val.npy'\n",
        "    X_TEST_PATH = 'X_test.npy'\n",
        "    Y_TEST_PATH = 'Y_test.npy'\n",
        "\n",
        "    print(f\"'{X_DATA_PATH}'와 '{Y_DATA_PATH}'에서 데이터셋 로드 중...\")\n",
        "\n",
        "    if not os.path.exists(X_DATA_PATH) or not os.path.exists(Y_DATA_PATH):\n",
        "        print(\"=\"*50)\n",
        "        print(f\"오류: '{X_DATA_PATH}' 또는 '{Y_DATA_PATH}' 파일을 찾을 수 없습니다.\")\n",
        "        print(\"데이터셋 파일이 스크립트와 동일한 디렉토리에 있는지 확인해주세요.\")\n",
        "        print(\"=\"*50)\n",
        "    else:\n",
        "        try:\n",
        "            # .npy 파일에서 각각 랜드마크와 레이블을 불러옵니다.\n",
        "            raw_landmarks = np.load(X_DATA_PATH)\n",
        "            raw_val = np.load(X_VAL_PATH)\n",
        "            raw_test = np.load(X_TEST_PATH)\n",
        "            labels = np.load(Y_DATA_PATH)\n",
        "            labels_val = np.load(Y_VAL_PATH)\n",
        "            labels_test = np.load(Y_TEST_PATH)\n",
        "            print(f\"로드 완료. 랜드마크: {raw_landmarks.shape}, 레이블: {labels.shape}\")\n",
        "\n",
        "            if raw_landmarks.shape[0] == 0:\n",
        "                print(\"오류: 로드된 데이터셋이 비어있습니다.\")\n",
        "            else:\n",
        "                # --- 2. 특징 공학 (Feature Engineering) ---\n",
        "\n",
        "                print(\"\\n특징 공학(Feature Engineering) 적용 중...\")\n",
        "                features = []\n",
        "                valid_labels = []\n",
        "\n",
        "                for i, lm in enumerate(raw_landmarks):\n",
        "                    feature_vector = feature_engineering(lm)\n",
        "                    # 특징 추출에 성공한(None이 아닌) 샘플만 사용\n",
        "                    if feature_vector is not None:\n",
        "                        features.append(feature_vector)\n",
        "                        valid_labels.append(labels[i])\n",
        "                features_val = []\n",
        "                valid_labels_val = []\n",
        "\n",
        "                for i, lm in enumerate(raw_val):\n",
        "                    feature_vector = feature_engineering(lm)\n",
        "                    # 특징 추출에 성공한(None이 아닌) 샘플만 사용\n",
        "                    if feature_vector is not None:\n",
        "                        features_val.append(feature_vector)\n",
        "                        valid_labels_val.append(labels_val[i])\n",
        "\n",
        "                features_test = []\n",
        "                valid_labels_test = []\n",
        "\n",
        "                for i, lm in enumerate(raw_test):\n",
        "                    feature_vector = feature_engineering(lm)\n",
        "                    # 특징 추출에 성공한(None이 아닌) 샘플만 사용\n",
        "                    if feature_vector is not None:\n",
        "                        features_test.append(feature_vector)\n",
        "                        valid_labels_test.append(labels_test[i])\n",
        "\n",
        "                # X: (n_valid_samples, n_features)\n",
        "                # y: (n_valid_samples,)\n",
        "                X_train = np.array(features)\n",
        "                y_train = np.array(valid_labels)\n",
        "                X_val = np.array(features_val)\n",
        "                y_val = np.array(valid_labels_val)\n",
        "                X_test = np.array(features_test)\n",
        "                y_test = np.array(valid_labels_test)\n",
        "\n",
        "                if X_train.shape[0] == 0:\n",
        "                     print(\"오류: 모든 샘플에서 특징 공학(각도 계산 등)에 실패했습니다.\")\n",
        "                     print(\"데이터셋의 가시성(visibility) 값을 확인해주세요.\")\n",
        "                else:\n",
        "\n",
        "                    print(f\"학습 데이터: {X_train.shape[0]}개 / 테스트 데이터: {X_test.shape[0]}개\")\n",
        "\n",
        "                    # --- 4. 모델 학습 ---\n",
        "                    # 1. 인덱스 배열 생성 (0부터 N-1까지)\n",
        "                    indices = np.arange(X_train.shape[0])\n",
        "\n",
        "                    # 2. 인덱스 무작위 섞기\n",
        "                    np.random.shuffle(indices)\n",
        "\n",
        "                    # 3. 섞인 인덱스로 X와 y 재배열 (짝 유지됨)\n",
        "                    X_train = X_train[indices]\n",
        "                    y_train = y_train[indices]\n",
        "\n",
        "                    # 입력 차원(input_shape)은 특징 벡터의 크기입니다. (여기서는 8)\n",
        "                    model = build_model(input_shape=X_train.shape[1])\n",
        "                    model.summary()\n",
        "\n",
        "                    print(\"\\n모델 학습 시작...\")\n",
        "                    history = model.fit(\n",
        "                        X_train,\n",
        "                        y_train,\n",
        "                        epochs=500,\n",
        "                        batch_size=16,\n",
        "                        validation_data=(X_val, y_val),\n",
        "                        callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)]\n",
        "                    )\n",
        "\n",
        "                    print(\"모델 학습 완료.\")\n",
        "\n",
        "                    # --- 5. 모델 평가 ---\n",
        "                    loss, accuracy = model.evaluate(X_test, y_test)\n",
        "                    print(f\"\\n테스트 데이터 평가 결과:\")\n",
        "                    print(f\"Loss (손실): {loss:.4f}\")\n",
        "                    print(f\"Accuracy (정확도): {accuracy:.4f}\")\n",
        "\n",
        "                    # --- 6. 모델 저장 ---\n",
        "                    model.save(\"All_pose_classifier_keras.h5\")\n",
        "                    print(\"학습된 모델을 'All_pose_classifier_keras.h5'로 저장했습니다.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"오류: 데이터셋 로드 또는 처리 중 예외 발생: {e}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Dkuzqwvtoev"
      },
      "source": [
        "## RandomForest (val_accuracy = 0.8688)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "stotQbNEf7cP",
        "outputId": "689ead73-aec5-4082-dc1b-97bdc20f79dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "데이터 전처리 중...\n",
            "데이터 셔플링 중...\n",
            "\n",
            "[Random Forest] 학습 시작 (데이터 개수: 2139개)...\n",
            "학습 완료.\n",
            "\n",
            "테스트 데이터 평가 결과:\n",
            "Accuracy (정확도): 0.9040\n",
            "\n",
            "분류 보고서:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.82      0.90       133\n",
            "           1       0.83      1.00      0.91       117\n",
            "\n",
            "    accuracy                           0.90       250\n",
            "   macro avg       0.91      0.91      0.90       250\n",
            "weighted avg       0.92      0.90      0.90       250\n",
            "\n",
            "모델 저장 완료: 'All_pose_classifier_rf.pkl'\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import joblib  # scikit-learn 모델 저장용\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# --- 메인 실행 로직 ---\n",
        "if __name__ == \"__main__\":\n",
        "    X_DATA_PATH = 'X_train.npy'; Y_DATA_PATH = 'Y_train.npy'\n",
        "    X_TEST_PATH = 'X_test.npy'; Y_TEST_PATH = 'Y_test.npy'\n",
        "\n",
        "    if not os.path.exists(X_DATA_PATH):\n",
        "        print(\"데이터 파일 없음\"); exit()\n",
        "\n",
        "    try:\n",
        "        raw_landmarks = np.load(X_DATA_PATH)\n",
        "        labels = np.load(Y_DATA_PATH)\n",
        "        raw_test = np.load(X_TEST_PATH)\n",
        "        labels_test = np.load(Y_TEST_PATH)\n",
        "\n",
        "        # 데이터 처리 함수\n",
        "        def process_data(raw_x, raw_y):\n",
        "            processed_x, processed_y = [], []\n",
        "            for i, lm in enumerate(raw_x):\n",
        "                fv = feature_engineering(lm)\n",
        "                if fv is not None:\n",
        "                    processed_x.append(fv)\n",
        "                    processed_y.append(raw_y[i])\n",
        "            return np.array(processed_x), np.array(processed_y)\n",
        "\n",
        "        print(\"데이터 전처리 중...\")\n",
        "        X_train, y_train = process_data(raw_landmarks, labels)\n",
        "        X_test, y_test = process_data(raw_test, labels_test)\n",
        "\n",
        "        # --- 셔플링 (Shuffling) ---\n",
        "        print(\"데이터 셔플링 중...\")\n",
        "        indices = np.arange(X_train.shape[0])\n",
        "        np.random.shuffle(indices)\n",
        "        X_train = X_train[indices]\n",
        "        y_train = y_train[indices]\n",
        "\n",
        "        # --- Random Forest 모델 학습 ---\n",
        "        print(f\"\\n[Random Forest] 학습 시작 (데이터 개수: {len(X_train)}개)...\")\n",
        "        # n_estimators: 트리의 개수 (보통 100~500)\n",
        "        rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "        rf_model.fit(X_train, y_train)\n",
        "        print(\"학습 완료.\")\n",
        "\n",
        "        # --- 모델 평가 ---\n",
        "        y_pred = rf_model.predict(X_test)\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "        print(f\"\\n테스트 데이터 평가 결과:\")\n",
        "        print(f\"Accuracy (정확도): {accuracy:.4f}\")\n",
        "        print(\"\\n분류 보고서:\")\n",
        "        print(classification_report(y_test, y_pred))\n",
        "\n",
        "        # --- 모델 저장 ---\n",
        "        joblib.dump(rf_model, \"All_pose_classifier_rf.pkl\")\n",
        "        print(\"모델 저장 완료: 'All_pose_classifier_rf.pkl'\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"오류 발생: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itZJbt5_toe1"
      },
      "source": [
        "## Support Vector Machine (val_accuracy = 0.9210)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqFSiCEcgOkM",
        "outputId": "8d39e760-2796-4b92-d4ca-ed154b89de35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "데이터 전처리 중 (신뢰도 포함)...\n",
            "특징 벡터 차원: 152\n",
            "데이터 셔플링 중...\n",
            "\n",
            "[SVM] 학습 준비 (데이터 개수: 2139개)...\n",
            "교차 검증(Cross Validation) 진행 중...\n",
            " >> 5-Fold 검증 정확도: [0.92757009 0.92757009 0.93691589 0.95560748 0.96487119]\n",
            " >> 평균 검증 정확도: 0.9425\n",
            "최종 모델 학습 중...\n",
            "\n",
            "테스트 데이터 평가 결과:\n",
            "Accuracy (정확도): 0.6720\n",
            "\n",
            "분류 보고서:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.38      0.55       133\n",
            "           1       0.59      1.00      0.74       117\n",
            "\n",
            "    accuracy                           0.67       250\n",
            "   macro avg       0.79      0.69      0.65       250\n",
            "weighted avg       0.81      0.67      0.64       250\n",
            "\n",
            "모델 저장 완료: 'All_pose_classifier_svm.pkl'\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import joblib\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "\n",
        "# --- 메인 실행 로직 ---\n",
        "if __name__ == \"__main__\":\n",
        "    X_DATA_PATH = 'X_train.npy'; Y_DATA_PATH = 'Y_train.npy'\n",
        "    X_TEST_PATH = 'X_test.npy'; Y_TEST_PATH = 'Y_test.npy'\n",
        "\n",
        "    if not os.path.exists(X_DATA_PATH):\n",
        "        print(\"데이터 파일 없음\"); exit()\n",
        "\n",
        "    try:\n",
        "        raw_landmarks = np.load(X_DATA_PATH)\n",
        "        labels = np.load(Y_DATA_PATH)\n",
        "        raw_test = np.load(X_TEST_PATH)\n",
        "        labels_test = np.load(Y_TEST_PATH)\n",
        "\n",
        "        def process_data(raw_x, raw_y):\n",
        "            processed_x, processed_y = [], []\n",
        "            for i, lm in enumerate(raw_x):\n",
        "                fv = feature_engineering(lm)\n",
        "                if fv is not None:\n",
        "                    processed_x.append(fv)\n",
        "                    processed_y.append(raw_y[i])\n",
        "            return np.array(processed_x), np.array(processed_y)\n",
        "\n",
        "        print(\"데이터 전처리 중 (신뢰도 포함)...\")\n",
        "        X_train, y_train = process_data(raw_landmarks, labels)\n",
        "        X_test, y_test = process_data(raw_test, labels_test)\n",
        "\n",
        "        print(f\"특징 벡터 차원: {X_train.shape[1]}\")\n",
        "\n",
        "        # --- 셔플링 (Shuffling) ---\n",
        "        print(\"데이터 셔플링 중...\")\n",
        "        indices = np.arange(X_train.shape[0])\n",
        "        np.random.shuffle(indices)\n",
        "        X_train = X_train[indices]\n",
        "        y_train = y_train[indices]\n",
        "\n",
        "        # --- SVM 모델 정의 ---\n",
        "        print(f\"\\n[SVM] 학습 준비 (데이터 개수: {len(X_train)}개)...\")\n",
        "\n",
        "        # SVM 파이프라인 (스케일링 + SVM)\n",
        "        svm_model = make_pipeline(\n",
        "            StandardScaler(),\n",
        "            SVC(kernel='rbf', C=1.0, probability=True, random_state=42)\n",
        "        )\n",
        "\n",
        "        # --- 1. 교차 검증 (Validation) ---\n",
        "        print(\"교차 검증(Cross Validation) 진행 중...\")\n",
        "        val_scores = cross_val_score(svm_model, X_train, y_train, cv=5)\n",
        "        print(f\" >> 5-Fold 검증 정확도: {val_scores}\")\n",
        "        print(f\" >> 평균 검증 정확도: {np.mean(val_scores):.4f}\")\n",
        "\n",
        "        # --- 2. 전체 데이터로 최종 학습 ---\n",
        "        print(\"최종 모델 학습 중...\")\n",
        "        svm_model.fit(X_train, y_train)\n",
        "\n",
        "        # --- 모델 평가 ---\n",
        "        y_pred = svm_model.predict(X_test)\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "        print(f\"\\n테스트 데이터 평가 결과:\")\n",
        "        print(f\"Accuracy (정확도): {accuracy:.4f}\")\n",
        "        print(\"\\n분류 보고서:\")\n",
        "        print(classification_report(y_test, y_pred))\n",
        "\n",
        "        # --- 모델 저장 ---\n",
        "        joblib.dump(svm_model, \"All_pose_classifier_svm.pkl\")\n",
        "        print(\"모델 저장 완료: 'All_pose_classifier_svm.pkl'\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"오류 발생: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3jBv-xCtoe2"
      },
      "source": [
        "## Log_Regression(val_accuracy = 0.5708)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdNdfX0itoe3",
        "outputId": "6de3b0c4-c73e-44dd-feb8-21a0e45ce3cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 모델 학습 및 환경 준비 완료\n",
            "\n",
            "--- 🧪 모델 검증 결과 (Test Set) ---\n",
            "✅ 정확도: 94.81%\n",
            "\n",
            "[ 혼동 행렬 (Confusion Matrix) ]\n",
            "[[110   0]\n",
            " [ 11  91]]\n",
            "\n",
            "[ 분류 리포트 (Classification Report) ]\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            " Bad Posture (0)       0.91      1.00      0.95       110\n",
            "Good Posture (1)       1.00      0.89      0.94       102\n",
            "\n",
            "        accuracy                           0.95       212\n",
            "       macro avg       0.95      0.95      0.95       212\n",
            "    weighted avg       0.95      0.95      0.95       212\n",
            "\n",
            "-----------------------------------\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        "import mediapipe as mp\n",
        "import cv2\n",
        "\n",
        "X_TRAIN_PATH = 'X_train.npy'\n",
        "Y_TRAIN_PATH = 'Y_train.npy'\n",
        "X_TEST_PATH = 'X_val.npy'\n",
        "Y_TEST_PATH = 'Y_val.npy'\n",
        "\n",
        "raw_landmarks = np.load(X_TRAIN_PATH)\n",
        "labels = np.load(Y_TRAIN_PATH)\n",
        "test_landmarks = np.load(X_TEST_PATH)\n",
        "test_labels = np.load(Y_TEST_PATH)\n",
        "\n",
        "features = []\n",
        "valid_labels = []\n",
        "test_features = []\n",
        "testlabels = []\n",
        "\n",
        "for i, lm in enumerate(raw_landmarks):\n",
        "    feature_vector = feature_engineering(lm)\n",
        "    # 특징 추출에 성공한(None이 아닌) 샘플만 사용\n",
        "    if feature_vector is not None:\n",
        "        features.append(feature_vector)\n",
        "        valid_labels.append(labels[i])\n",
        "\n",
        "for i, lm in enumerate(test_landmarks):\n",
        "    feature_vector = feature_engineering(lm)\n",
        "    # 특징 추출에 성공한(None이 아닌) 샘플만 사용\n",
        "    if feature_vector is not None:\n",
        "        test_features.append(feature_vector)\n",
        "        testlabels.append(test_labels[i])\n",
        "\n",
        "X_train = np.array(features)\n",
        "Y_train = np.array(valid_labels)\n",
        "\n",
        "X_test = np.array(test_features)\n",
        "Y_test = np.array(testlabels)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "log_reg_model = LogisticRegression(solver='liblinear', random_state=42)\n",
        "log_reg_model.fit(X_train_scaled, Y_train)\n",
        "\n",
        "print(\"✅ 모델 학습 및 환경 준비 완료\")\n",
        "\n",
        "# --- 2. [추가] 모델 검증 코드 ---\n",
        "print(\"\\n--- 🧪 모델 검증 결과 (Test Set) ---\")\n",
        "Y_pred = log_reg_model.predict(X_test_scaled)\n",
        "\n",
        "# 정확도 (Accuracy)\n",
        "accuracy = accuracy_score(Y_test, Y_pred)\n",
        "print(f\"✅ 정확도: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# 혼동 행렬 (Confusion Matrix)\n",
        "print(\"\\n[ 혼동 행렬 (Confusion Matrix) ]\")\n",
        "print(confusion_matrix(Y_test, Y_pred))\n",
        "\n",
        "# 분류 리포트 (Precision, Recall, F1-score)\n",
        "# target_names는 0번 클래스와 1번 클래스의 이름을 지정합니다.\n",
        "print(\"\\n[ 분류 리포트 (Classification Report) ]\")\n",
        "print(classification_report(Y_test, Y_pred, target_names=['Bad Posture (0)', 'Good Posture (1)']))\n",
        "print(\"-----------------------------------\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python (motion_transformer)",
      "language": "python",
      "name": "motion_transformer"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.23"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}